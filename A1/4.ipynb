{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IM6CZzW_CH0"
      },
      "source": [
        "# Informer Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdaIHYx4_ECL"
      },
      "source": [
        "## Download code and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA_i2gbl-rn-",
        "outputId": "bb9bff72-3ac6-499f-a3d1-022137e657f1"
      },
      "source": [
        "!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
        "!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Informer2020'...\n",
            "remote: Enumerating objects: 576, done.\u001b[K\n",
            "remote: Counting objects: 100% (222/222), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 576 (delta 199), reused 188 (delta 188), pack-reused 354\u001b[K\n",
            "Receiving objects: 100% (576/576), 6.48 MiB | 17.23 MiB/s, done.\n",
            "Resolving deltas: 100% (336/336), done.\n",
            "Cloning into 'ETDataset'...\n",
            "remote: Enumerating objects: 187, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 187 (delta 25), reused 20 (delta 20), pack-reused 159\u001b[K\n",
            "Receiving objects: 100% (187/187), 3.86 MiB | 12.90 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "ETDataset  Informer2020  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5GFng7v7Eq0"
      },
      "source": [
        "import sys\n",
        "if not 'Informer2020' in sys.path:\n",
        "    sys.path += ['Informer2020']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW9TS6jp_YXc"
      },
      "source": [
        "# !pip install -r ./Informer2020/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIjZdN5e_SWe"
      },
      "source": [
        "## Experiments: Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdt-Kwc_RRZ"
      },
      "source": [
        "from utils.tools import dotdict\n",
        "from exp.exp_informer import Exp_Informer\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Probsparse attention and Dataset using is ETTh1"
      ],
      "metadata": {
        "id": "mTgiYpfLDF5W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mx2dnwY9dWi"
      },
      "source": [
        "args = dotdict()\n",
        "\n",
        "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
        "\n",
        "args.data = 'ETTh1' # data\n",
        "args.root_path = './ETDataset/ETT-small/' # root path of data file\n",
        "args.data_path = 'ETTh1.csv' # data file\n",
        "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
        "args.target = 'OT' # target feature in S or MS task\n",
        "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
        "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
        "\n",
        "args.seq_len = 96 # input sequence length of Informer encoder\n",
        "args.label_len = 48 # start token length of Informer decoder\n",
        "args.pred_len = 24 # prediction sequence length\n",
        "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
        "\n",
        "args.enc_in = 7 # encoder input size\n",
        "args.dec_in = 7 # decoder input size\n",
        "args.c_out = 7 # output size\n",
        "args.factor = 5 # probsparse attn factor\n",
        "args.d_model = 512 # dimension of model\n",
        "args.n_heads = 8 # num of heads\n",
        "args.e_layers = 2 # num of encoder layers\n",
        "args.d_layers = 1 # num of decoder layers\n",
        "args.d_ff = 2048 # dimension of fcn in model\n",
        "args.dropout = 0.05 # dropout\n",
        "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'gelu' # activation\n",
        "args.distil = True # whether to use distilling in encoder\n",
        "args.output_attention = False # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "args.padding = 0\n",
        "args.freq = 'h'\n",
        "\n",
        "args.batch_size = 32\n",
        "args.learning_rate = 0.0001\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "args.use_amp = False # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 0\n",
        "args.itr = 1\n",
        "args.train_epochs = 6\n",
        "args.patience = 3\n",
        "args.des = 'exp'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "args.gpu = 0\n",
        "\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_BCYODAwKl9"
      },
      "source": [
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "if args.use_gpu and args.use_multi_gpu:\n",
        "    args.devices = args.devices.replace(' ','')\n",
        "    device_ids = args.devices.split(',')\n",
        "    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    args.gpu = args.device_ids[0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53o3pZ809p-a"
      },
      "source": [
        "# Set augments by using data name\n",
        "data_parser = {\n",
        "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "}\n",
        "if args.data in data_parser.keys():\n",
        "    data_info = data_parser[args.data]\n",
        "    args.data_path = data_info['data']\n",
        "    args.target = data_info['T']\n",
        "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ5Q2vyKwSfk"
      },
      "source": [
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywY-umrw-mHO",
        "outputId": "7c77f681-81a6-4980-fd6e-fa37266e0703"
      },
      "source": [
        "print('Args in experiment:')\n",
        "print(args)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "{'model': 'informer', 'data': 'ETTh1', 'root_path': './ETDataset/ETT-small/', 'data_path': 'ETTh1.csv', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './informer_checkpoints', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 6, 'patience': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'h'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVHZhRB4-on9"
      },
      "source": [
        "Exp = Exp_Informer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "928tzaA2AA2g",
        "outputId": "e3ccc85b-e55f-403b-e5d6-b3eca8a00ed7"
      },
      "source": [
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features,\n",
        "                args.seq_len, args.label_len, args.pred_len,\n",
        "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
        "\n",
        "    # set experiments\n",
        "    exp = Exp(args)\n",
        "\n",
        "    # train\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)\n",
        "\n",
        "    # test\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 8521\n",
            "val 2857\n",
            "test 2857\n",
            "\titers: 100, epoch: 1 | loss: 0.4772281\n",
            "\tspeed: 0.1674s/iter; left time: 250.5771s\n",
            "\titers: 200, epoch: 1 | loss: 0.3483168\n",
            "\tspeed: 0.0670s/iter; left time: 93.6301s\n",
            "Epoch: 1 cost time: 27.649043560028076\n",
            "Epoch: 1, Steps: 266 | Train Loss: 0.4158556 Vali Loss: 0.6581546 Test Loss: 0.4921865\n",
            "Validation loss decreased (inf --> 0.658155).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.2477820\n",
            "\tspeed: 0.1652s/iter; left time: 203.3329s\n",
            "\titers: 200, epoch: 2 | loss: 0.2310081\n",
            "\tspeed: 0.0682s/iter; left time: 77.1035s\n",
            "Epoch: 2 cost time: 18.250289916992188\n",
            "Epoch: 2, Steps: 266 | Train Loss: 0.2594950 Vali Loss: 0.6141768 Test Loss: 0.5607302\n",
            "Validation loss decreased (0.658155 --> 0.614177).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.1660926\n",
            "\tspeed: 0.1619s/iter; left time: 156.2493s\n",
            "\titers: 200, epoch: 3 | loss: 0.1563166\n",
            "\tspeed: 0.0699s/iter; left time: 60.4473s\n",
            "Epoch: 3 cost time: 18.56778383255005\n",
            "Epoch: 3, Steps: 266 | Train Loss: 0.1997126 Vali Loss: 0.6731401 Test Loss: 0.6019856\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.1688161\n",
            "\tspeed: 0.1634s/iter; left time: 114.2183s\n",
            "\titers: 200, epoch: 4 | loss: 0.1539242\n",
            "\tspeed: 0.0725s/iter; left time: 43.4568s\n",
            "Epoch: 4 cost time: 18.88943076133728\n",
            "Epoch: 4, Steps: 266 | Train Loss: 0.1712118 Vali Loss: 0.6747075 Test Loss: 0.6723494\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.1834505\n",
            "\tspeed: 0.1655s/iter; left time: 71.6778s\n",
            "\titers: 200, epoch: 5 | loss: 0.1802762\n",
            "\tspeed: 0.0713s/iter; left time: 23.7359s\n",
            "Epoch: 5 cost time: 18.902802228927612\n",
            "Epoch: 5, Steps: 266 | Train Loss: 0.1569551 Vali Loss: 0.7122827 Test Loss: 0.7317492\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 2857\n",
            "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
            "test shape: (2848, 24, 7) (2848, 24, 7)\n",
            "mse:0.5603117346763611, mae:0.5423396825790405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Canonical attentionand Dataset using is ETTh1**"
      ],
      "metadata": {
        "id": "x3PxpKNcDT9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = dotdict()\n",
        "\n",
        "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
        "\n",
        "args.data = 'ETTh1' # data\n",
        "args.root_path = './ETDataset/ETT-small/' # root path of data file\n",
        "args.data_path = 'ETTh1.csv' # data file\n",
        "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
        "args.target = 'OT' # target feature in S or MS task\n",
        "args.freq = 'h' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
        "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
        "\n",
        "args.seq_len = 96 # input sequence length of Informer encoder\n",
        "args.label_len = 48 # start token length of Informer decoder\n",
        "args.pred_len = 24 # prediction sequence length\n",
        "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
        "\n",
        "args.enc_in = 7 # encoder input size\n",
        "args.dec_in = 7 # decoder input size\n",
        "args.c_out = 7 # output size\n",
        "args.factor = 5 # probsparse attn factor\n",
        "args.d_model = 512 # dimension of model\n",
        "args.n_heads = 8 # num of heads\n",
        "args.e_layers = 2 # num of encoder layers\n",
        "args.d_layers = 1 # num of decoder layers\n",
        "args.d_ff = 2048 # dimension of fcn in model\n",
        "args.dropout = 0.05 # dropout\n",
        "args.attn = 'full' # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'gelu' # activation\n",
        "args.distil = True # whether to use distilling in encoder\n",
        "args.output_attention = False # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "args.padding = 0\n",
        "args.freq = 'h'\n",
        "\n",
        "args.batch_size = 32\n",
        "args.learning_rate = 0.0001\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "args.use_amp = False # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 0\n",
        "args.itr = 1\n",
        "args.train_epochs = 6\n",
        "args.patience = 3\n",
        "args.des = 'exp'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "args.gpu = 0\n",
        "\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'\n"
      ],
      "metadata": {
        "id": "kQhrNwtACt1L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "if args.use_gpu and args.use_multi_gpu:\n",
        "    args.devices = args.devices.replace(' ','')\n",
        "    device_ids = args.devices.split(',')\n",
        "    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    args.gpu = args.device_ids[0]"
      ],
      "metadata": {
        "id": "7ogvxifCCzWt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set augments by using data name\n",
        "data_parser = {\n",
        "    'ETTh1':{'data':'ETTh1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTh2':{'data':'ETTh2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTm1':{'data':'ETTm1.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "    'ETTm2':{'data':'ETTm2.csv','T':'OT','M':[7,7,7],'S':[1,1,1],'MS':[7,7,1]},\n",
        "}\n",
        "if args.data in data_parser.keys():\n",
        "    data_info = data_parser[args.data]\n",
        "    args.data_path = data_info['data']\n",
        "    args.target = data_info['T']\n",
        "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
      ],
      "metadata": {
        "id": "S21FgRmVC1g5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]"
      ],
      "metadata": {
        "id": "hXcqG0V2C1rn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Args in experiment:')\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqcnaJaUC6eV",
        "outputId": "fffdd96c-32dc-43b3-8981-0a6fd02cb83d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "{'model': 'informer', 'data': 'ETTh1', 'root_path': './ETDataset/ETT-small/', 'data_path': 'ETTh1.csv', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './informer_checkpoints', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'factor': 5, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'full', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 6, 'patience': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'h'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Exp = Exp_Informer"
      ],
      "metadata": {
        "id": "g-VEfFb-C83I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features,\n",
        "                args.seq_len, args.label_len, args.pred_len,\n",
        "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
        "\n",
        "    # set experiments\n",
        "    exp = Exp(args)\n",
        "\n",
        "    # train\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)\n",
        "\n",
        "    # test\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK9ougiWC_WA",
        "outputId": "9591a709-904f-4e9f-9dbb-45e95034761b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 8521\n",
            "val 2857\n",
            "test 2857\n",
            "\titers: 100, epoch: 1 | loss: 0.3570700\n",
            "\tspeed: 0.0628s/iter; left time: 94.0175s\n",
            "\titers: 200, epoch: 1 | loss: 0.3069236\n",
            "\tspeed: 0.0631s/iter; left time: 88.0940s\n",
            "Epoch: 1 cost time: 16.766761779785156\n",
            "Epoch: 1, Steps: 266 | Train Loss: 0.3724831 Vali Loss: 0.6837342 Test Loss: 0.5828947\n",
            "Validation loss decreased (inf --> 0.683734).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.2614771\n",
            "\tspeed: 0.1439s/iter; left time: 177.1948s\n",
            "\titers: 200, epoch: 2 | loss: 0.2578691\n",
            "\tspeed: 0.0641s/iter; left time: 72.5137s\n",
            "Epoch: 2 cost time: 17.028961896896362\n",
            "Epoch: 2, Steps: 266 | Train Loss: 0.2445351 Vali Loss: 0.6834506 Test Loss: 0.5525337\n",
            "Validation loss decreased (0.683734 --> 0.683451).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.2055816\n",
            "\tspeed: 0.1444s/iter; left time: 139.3376s\n",
            "\titers: 200, epoch: 3 | loss: 0.2043155\n",
            "\tspeed: 0.0647s/iter; left time: 55.9607s\n",
            "Epoch: 3 cost time: 17.201651573181152\n",
            "Epoch: 3, Steps: 266 | Train Loss: 0.1809352 Vali Loss: 0.6962857 Test Loss: 0.5463468\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.1469782\n",
            "\tspeed: 0.1446s/iter; left time: 101.0655s\n",
            "\titers: 200, epoch: 4 | loss: 0.1625196\n",
            "\tspeed: 0.0657s/iter; left time: 39.3278s\n",
            "Epoch: 4 cost time: 17.392745971679688\n",
            "Epoch: 4, Steps: 266 | Train Loss: 0.1525595 Vali Loss: 0.7656381 Test Loss: 0.5488769\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.1337523\n",
            "\tspeed: 0.1459s/iter; left time: 63.1820s\n",
            "\titers: 200, epoch: 5 | loss: 0.1368995\n",
            "\tspeed: 0.0662s/iter; left time: 22.0357s\n",
            "Epoch: 5 cost time: 17.543655395507812\n",
            "Epoch: 5, Steps: 266 | Train Loss: 0.1391584 Vali Loss: 0.7798102 Test Loss: 0.5615142\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atfull_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 2857\n",
            "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
            "test shape: (2848, 24, 7) (2848, 24, 7)\n",
            "mse:0.552533745765686, mae:0.5523127913475037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "     \n",
        "\n",
        "*   Output for Probsparse attention :\n",
        "   mse:0.5603117346763611\n",
        "mae:0.5423396825790405            \n",
        "*    Canonical attention :\n",
        "mse:0.552533745765686.\n",
        "mae:0.5523127913475037.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0kSFKCTwD4-P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a72iSjAxEDHD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}